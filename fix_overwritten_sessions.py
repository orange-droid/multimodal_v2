#!/usr/bin/env python3
"""
å®Œå…¨é‡æ–°è¿›è¡Œå¢å¼ºç‰ˆå­å›¾æå–
è¦†ç›–æ‰€æœ‰ä¼šè¯ï¼ˆ0-958ï¼‰ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„å¢å¼ºç‰ˆé€»è¾‘
"""

import os
import sys
import pickle
import logging
import time
from datetime import datetime
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥å¢å¼ºç‰ˆå­å›¾æå–å™¨
from src.prototype.universal_subgraph_extractor import UniversalSubgraphExtractor

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"complete_enhanced_subgraph_extraction_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__), log_file

def load_heterogeneous_graph(graph_path: str):
    """åŠ è½½å¼‚æ„å›¾"""
    print(f"ğŸ“Š åŠ è½½å¼‚æ„å›¾: {graph_path}")
    
    with open(graph_path, 'rb') as f:
        graph = pickle.load(f)
    
    # è·å–ä¼šè¯ä¿¡æ¯
    media_session_nodes = graph['media_session'].x
    total_sessions = len(media_session_nodes)
    
    print(f"âœ… å¼‚æ„å›¾åŠ è½½å®Œæˆ")
    print(f"   æ€»ä¼šè¯æ•°: {total_sessions}")
    print(f"   èŠ‚ç‚¹ç±»å‹: {list(graph.node_types)}")
    print(f"   è¾¹ç±»å‹: {list(graph.edge_types)}")
    
    return graph, total_sessions

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å®Œå…¨é‡æ–°è¿›è¡Œå¢å¼ºç‰ˆå­å›¾æå–...")
    print("ğŸ“‹ æœ¬æ¬¡å°†è¦†ç›–æ‰€æœ‰ä¼šè¯ï¼ˆ0-958ï¼‰ï¼Œä½¿ç”¨æœ€æ–°çš„å¢å¼ºç‰ˆé€»è¾‘")
    
    # è®¾ç½®æ—¥å¿—
    logger, log_file = setup_logging()
    logger.info("å¼€å§‹å®Œå…¨é‡æ–°è¿›è¡Œå¢å¼ºç‰ˆå­å›¾æå–")
    
    start_time = time.time()
    
    try:
        # é…ç½®å‚æ•°
        config = {
            'min_subgraph_size': 6,
            'max_subgraph_size': 15,
            'max_enumeration_combinations': 500,  # ä½¿ç”¨å®Œæ•´é…ç½®ï¼Œä¸é™åˆ¶
            'enable_multi_user_interactions': True,
            'enable_multi_size_extraction': True,
            'enable_complete_enumeration': True,
            'interaction_threshold': 0.1,
            'batch_size': 50,
            'save_frequency': 10
        }
        
        # æ•°æ®è·¯å¾„
        graph_path = "data/graphs/heterogeneous_graph_final.pkl"
        output_dir = "data/subgraphs/universal_enhanced"
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(graph_path):
            raise FileNotFoundError(f"å¼‚æ„å›¾æ–‡ä»¶ä¸å­˜åœ¨: {graph_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        # åŠ è½½å¼‚æ„å›¾
        graph, total_sessions = load_heterogeneous_graph(graph_path)
        
        # åˆ›å»ºå­å›¾æå–å™¨
        print("ğŸ”§ åˆå§‹åŒ–å¢å¼ºç‰ˆå­å›¾æå–å™¨...")
        extractor = UniversalSubgraphExtractor(config)
        
        # æå–æ‰€æœ‰ä¼šè¯çš„å­å›¾ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        print(f"\nğŸ¯ å¼€å§‹æå–æ‰€æœ‰ {total_sessions} ä¸ªä¼šè¯çš„å­å›¾...")
        
        total_subgraphs = 0
        failed_sessions = []
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
        with tqdm(total=total_sessions, desc="æå–è¿›åº¦", unit="ä¼šè¯") as pbar:
            for session_id in range(total_sessions):
                try:
                    # æ›´æ–°è¿›åº¦æ¡æè¿°
                    pbar.set_description(f"æå–ä¼šè¯ {session_id}")
                    
                    # æå–å•ä¸ªä¼šè¯çš„å­å›¾
                    session_subgraphs = extractor._extract_session_subgraphs_enhanced(
                        graph, f"media_session_{session_id}"
                    )
                    
                    if session_subgraphs:
                        # ä¿å­˜å­å›¾
                        output_file = os.path.join(output_dir, f"media_session_{session_id}_subgraphs.pkl")
                        with open(output_file, 'wb') as f:
                            pickle.dump(session_subgraphs, f)
                        
                        subgraph_count = len(session_subgraphs)
                        total_subgraphs += subgraph_count
                        
                        # æ›´æ–°è¿›åº¦æ¡åç¼€ä¿¡æ¯
                        pbar.set_postfix({
                            'å­å›¾æ•°': subgraph_count,
                            'æ€»è®¡': total_subgraphs,
                            'å¤±è´¥': len(failed_sessions)
                        })
                        
                        logger.info(f"ä¼šè¯ {session_id}: ç”Ÿæˆ {subgraph_count} ä¸ªå­å›¾")
                    else:
                        failed_sessions.append(session_id)
                        logger.warning(f"ä¼šè¯ {session_id}: æœªç”Ÿæˆä»»ä½•å­å›¾")
                        
                        pbar.set_postfix({
                            'å­å›¾æ•°': 0,
                            'æ€»è®¡': total_subgraphs,
                            'å¤±è´¥': len(failed_sessions)
                        })
                
                except Exception as e:
                    failed_sessions.append(session_id)
                    logger.error(f"ä¼šè¯ {session_id} å¤„ç†å¤±è´¥: {e}")
                    
                    pbar.set_postfix({
                        'å­å›¾æ•°': 0,
                        'æ€»è®¡': total_subgraphs,
                        'å¤±è´¥': len(failed_sessions)
                    })
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
        
        # è®¡ç®—è€—æ—¶
        end_time = time.time()
        duration = end_time - start_time
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        successful_sessions = total_sessions - len(failed_sessions)
        success_rate = (successful_sessions / total_sessions) * 100
        avg_subgraphs_per_session = total_subgraphs / successful_sessions if successful_sessions > 0 else 0
        
        print(f"\nğŸ‰ å®Œå…¨é‡æ–°æå–å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"   æ€»ä¼šè¯æ•°: {total_sessions}")
        print(f"   æˆåŠŸå¤„ç†: {successful_sessions} ({success_rate:.1f}%)")
        print(f"   å¤±è´¥ä¼šè¯: {len(failed_sessions)}")
        print(f"   æ€»å­å›¾æ•°: {total_subgraphs:,}")
        print(f"   å¹³å‡æ¯ä¼šè¯: {avg_subgraphs_per_session:.1f} ä¸ªå­å›¾")
        print(f"   æ€»è€—æ—¶: {duration:.2f} ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {total_sessions/duration:.1f} ä¼šè¯/ç§’")
        
        # è®°å½•åˆ°æ—¥å¿—
        logger.info("å®Œå…¨é‡æ–°æå–å®Œæˆ")
        logger.info(f"æˆåŠŸå¤„ç†: {successful_sessions}/{total_sessions} ({success_rate:.1f}%)")
        logger.info(f"æ€»å­å›¾æ•°: {total_subgraphs:,}")
        logger.info(f"å¹³å‡æ¯ä¼šè¯: {avg_subgraphs_per_session:.1f} ä¸ªå­å›¾")
        logger.info(f"æ€»è€—æ—¶: {duration:.2f} ç§’")
        
        if failed_sessions:
            print(f"\nâš ï¸  å¤±è´¥çš„ä¼šè¯: {failed_sessions[:10]}{'...' if len(failed_sessions) > 10 else ''}")
            logger.warning(f"å¤±è´¥çš„ä¼šè¯: {failed_sessions}")
        
        print(f"\nğŸ“ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜è‡³: {log_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"å®Œå…¨é‡æ–°æå–å¤±è´¥: {e}")
        print(f"âŒ å®Œå…¨é‡æ–°æå–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 