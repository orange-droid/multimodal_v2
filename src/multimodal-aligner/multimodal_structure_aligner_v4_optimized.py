#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆå¤šæ¨¡æ€ç»“æ„å¯¹é½å™¨ V4 - æ”¯æŒä»£è¡¨æ€§å­å›¾é€‰æ‹©
åœ¨åŸæœ‰åŠŸèƒ½åŸºç¡€ä¸Šï¼Œæ·»åŠ ä»£è¡¨æ€§å­å›¾é€‰æ‹©ç­–ç•¥ï¼Œå‡å°‘è®¡ç®—æ—¶é—´ï¼Œæé«˜æµ‹è¯•æ•ˆç‡

ä¸»è¦ä¼˜åŒ–ï¼š
1. ä»£è¡¨æ€§å­å›¾é€‰æ‹©ï¼šä»æ¯ä¸ªä¼šè¯çš„å¤šä¸ªè¯„è®ºä¸­é€‰æ‹©ä»£è¡¨æ€§å­å›¾
2. æ™ºèƒ½é‡‡æ ·ç­–ç•¥ï¼šç»“åˆæ”»å‡»æ€§å¼ºåº¦å’Œå¤šæ ·æ€§çš„é‡‡æ ·ç®—æ³•
3. æ‰¹é‡å¤„ç†ä¼˜åŒ–ï¼šå‡å°‘é‡å¤è®¡ç®—ï¼Œæé«˜æ•ˆç‡
4. ç‰¹å¾èšåˆä¼˜åŒ–ï¼šåŸºäºé€‰å®šå­å›¾çš„é«˜æ•ˆç‰¹å¾èšåˆ

æ›´æ–°æ—¶é—´ï¼š2025-06-09
åŸºäºï¼šmultimodal_structure_aligner_v4.py
"""

import numpy as np
import json
import pickle
from typing import Dict, List, Optional, Set, Any, Tuple
import logging
import random
from pathlib import Path

# å¯¼å…¥åŸºç¡€ç±»
from multimodal_structure_aligner_v4 import MultimodalStructureAlignerV4

class MultimodalStructureAlignerV4Optimized(MultimodalStructureAlignerV4):
    """
    ä¼˜åŒ–ç‰ˆå¤šæ¨¡æ€ç»“æ„å¯¹é½å™¨
    
    æ–°å¢åŠŸèƒ½ï¼š
    1. ä»£è¡¨æ€§å­å›¾é€‰æ‹©ç­–ç•¥
    2. æ™ºèƒ½é‡‡æ ·ç®—æ³•
    3. æ‰¹é‡å¤„ç†ä¼˜åŒ–
    """
    
    def __init__(self, config: Dict[str, Any]):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(config)
        
        # ä¼˜åŒ–é…ç½®
        self.optimization_config = {
            'representative_subgraph_count': config.get('representative_subgraph_count', 3),  # æ¯ä¸ªä¼šè¯é€‰æ‹©3ä¸ªä»£è¡¨æ€§å­å›¾
            'sampling_strategy': config.get('sampling_strategy', 'diverse_aggressive'),      # é‡‡æ ·ç­–ç•¥
            'min_subgraph_size': config.get('min_subgraph_size', 6),                        # æœ€å°å­å›¾å¤§å°
            'max_subgraph_size': config.get('max_subgraph_size', 15),                       # æœ€å¤§å­å›¾å¤§å°
            'aggressive_comment_ratio': config.get('aggressive_comment_ratio', 0.7),        # æ”»å‡»æ€§è¯„è®ºæ¯”ä¾‹
            'enable_quality_filtering': config.get('enable_quality_filtering', True)        # å¯ç”¨è´¨é‡è¿‡æ»¤
        }
        
        print(f"âœ… ä¼˜åŒ–ç‰ˆå¯¹é½å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ä»£è¡¨æ€§å­å›¾æ•°é‡: {self.optimization_config['representative_subgraph_count']}")
        print(f"   é‡‡æ ·ç­–ç•¥: {self.optimization_config['sampling_strategy']}")
    
    def align_session_with_prototypes_optimized(self, session_id: str) -> Dict:
        """
        ä¼˜åŒ–ç‰ˆä¼šè¯åŸå‹å¯¹é½ - ä½¿ç”¨ä»£è¡¨æ€§å­å›¾
        """
        if not self.prototypes:
            return {
                'session_id': session_id,
                'status': 'no_prototypes',
                'similarities': [],
                'max_similarity': 0.0,
                'prediction': 'normal',
                'subgraph_count': 0
            }
        
        # 1. è·å–ä¼šè¯çš„æ‰€æœ‰è¯„è®ºèŠ‚ç‚¹
        session_comments = self._get_session_comments(session_id)
        if not session_comments:
            return {
                'session_id': session_id,
                'status': 'no_comments',
                'similarities': [],
                'max_similarity': 0.0,
                'prediction': 'normal',
                'subgraph_count': 0
            }
        
        # 2. é€‰æ‹©ä»£è¡¨æ€§è¯„è®ºä½œä¸ºå­å›¾ä¸­å¿ƒ
        representative_comments = self._select_representative_comments(
            session_comments, session_id
        )
        
        if not representative_comments:
            return {
                'session_id': session_id,
                'status': 'no_representative_comments',
                'similarities': [],
                'max_similarity': 0.0,
                'prediction': 'normal',
                'subgraph_count': 0
            }
        
        print(f"   é€‰æ‹©äº† {len(representative_comments)} ä¸ªä»£è¡¨æ€§è¯„è®º")
        
        # 3. ä¸ºæ¯ä¸ªä»£è¡¨æ€§è¯„è®ºæå–å­å›¾å¹¶è®¡ç®—ç›¸ä¼¼åº¦
        all_similarities = []
        subgraph_results = []
        
        for comment_idx in representative_comments:
            try:
                # æå–å­å›¾
                subgraph = self.extract_session_subgraph(
                    session_id, 
                    target_size=random.randint(
                        self.optimization_config['min_subgraph_size'],
                        self.optimization_config['max_subgraph_size']
                    )
                )
                
                if not subgraph:
                    continue
                
                # è®¡ç®—ä¸æ‰€æœ‰åŸå‹çš„ç›¸ä¼¼åº¦
                subgraph_similarities = []
                for i, prototype in enumerate(self.prototypes):
                    similarity = self.calculate_prototype_similarity(subgraph, prototype)
                    
                    # æå–åŸå‹æƒ…æ„Ÿåˆ†æ•°
                    prototype_emotion = 0.0
                    if 'representative_subgraph' in prototype:
                        emotion_features = prototype['representative_subgraph'].get('emotion_features', {})
                        prototype_emotion = emotion_features.get('avg_text_length', 0.0)
                    
                    subgraph_similarities.append({
                        'prototype_id': i,
                        'similarity': similarity,
                        'prototype_emotion': prototype_emotion
                    })
                
                all_similarities.extend(subgraph_similarities)
                subgraph_results.append({
                    'comment_center': comment_idx,
                    'subgraph': subgraph,
                    'similarities': subgraph_similarities
                })
                
            except Exception as e:
                print(f"âš ï¸ ä»£è¡¨æ€§è¯„è®º {comment_idx} å­å›¾æå–å¤±è´¥: {e}")
                continue
        
        if not all_similarities:
            return {
                'session_id': session_id,
                'status': 'extraction_failed',
                'similarities': [],
                'max_similarity': 0.0,
                'prediction': 'normal',
                'subgraph_count': 0
            }
        
        # 4. èšåˆå¤šä¸ªå­å›¾çš„ç›¸ä¼¼åº¦ç»“æœ
        aggregated_similarities = self._aggregate_similarities(all_similarities)
        max_similarity = max(sim['similarity'] for sim in aggregated_similarities) if aggregated_similarities else 0.0
        
        # 5. é¢„æµ‹ï¼ˆåŸºäºç›¸ä¼¼åº¦é˜ˆå€¼ï¼‰
        threshold = self.config.get('similarity_threshold', 0.6)
        prediction = 'bullying' if max_similarity >= threshold else 'normal'
        
        # 6. è®¡ç®—èšåˆç‰¹å¾
        aggregated_features = self._compute_aggregated_features(
            subgraph_results, aggregated_similarities
        )
        
        return {
            'session_id': session_id,
            'status': 'success',
            'similarities': aggregated_similarities,
            'max_similarity': max_similarity,
            'prediction': prediction,
            'threshold_used': threshold,
            'subgraph_count': len(subgraph_results),
            'representative_comments': representative_comments,
            'subgraph_results': subgraph_results,
            'aggregated_features': aggregated_features
        }
    
    def _get_session_comments(self, session_id: str) -> List[int]:
        """è·å–ä¼šè¯çš„æ‰€æœ‰è¯„è®ºèŠ‚ç‚¹"""
        try:
            # ä½¿ç”¨çˆ¶ç±»çš„æ–¹æ³•è·å–ä¼šè¯è¯„è®º
            if session_id not in self.session_to_nodes:
                return []
            
            comment_nodes = self.session_to_nodes[session_id]
            
            # è¿‡æ»¤å‡ºè¯„è®ºèŠ‚ç‚¹èŒƒå›´å†…çš„èŠ‚ç‚¹
            comment_start = self.node_start_indices.get('comment', 55038)
            comment_end = self.node_start_indices.get('word', 132441)  # ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ç±»å‹çš„èµ·å§‹ç´¢å¼•
            
            valid_comments = [
                node for node in comment_nodes 
                if comment_start <= node < comment_end
            ]
            
            return valid_comments
            
        except Exception as e:
            print(f"âŒ è·å–ä¼šè¯è¯„è®ºå¤±è´¥: {e}")
            return []
    
    def _select_representative_comments(self, comment_nodes: List[int], session_id: str) -> List[int]:
        """é€‰æ‹©ä»£è¡¨æ€§è¯„è®ºèŠ‚ç‚¹"""
        target_count = self.optimization_config['representative_subgraph_count']
        strategy = self.optimization_config['sampling_strategy']
        
        if len(comment_nodes) <= target_count:
            return comment_nodes
        
        if strategy == 'diverse_aggressive':
            return self._diverse_aggressive_sampling(comment_nodes, target_count)
        elif strategy == 'high_aggressive':
            return self._high_aggressive_sampling(comment_nodes, target_count)
        elif strategy == 'random':
            return random.sample(comment_nodes, target_count)
        elif strategy == 'balanced':
            return self._balanced_sampling(comment_nodes, target_count)
        else:
            return self._diverse_aggressive_sampling(comment_nodes, target_count)
    
    def _diverse_aggressive_sampling(self, comment_nodes: List[int], target_count: int) -> List[int]:
        """å¤šæ ·æ€§æ”»å‡»æ€§é‡‡æ ·"""
        if not comment_nodes:
            return []
        
        comment_scores = []
        for comment_idx in comment_nodes:
            aggression_score = self._estimate_comment_aggressiveness(comment_idx)
            comment_scores.append((comment_idx, aggression_score))
        
        comment_scores.sort(key=lambda x: x[1], reverse=True)
        
        aggressive_count = min(int(target_count * 0.7), len(comment_scores))
        diverse_count = target_count - aggressive_count
        
        selected = []
        
        for i in range(aggressive_count):
            if i < len(comment_scores):
                selected.append(comment_scores[i][0])
        
        remaining_comments = [score[0] for score in comment_scores[aggressive_count:]]
        if remaining_comments and diverse_count > 0:
            diverse_selected = random.sample(
                remaining_comments, 
                min(diverse_count, len(remaining_comments))
            )
            selected.extend(diverse_selected)
        
        return selected[:target_count]
    
    def _high_aggressive_sampling(self, comment_nodes: List[int], target_count: int) -> List[int]:
        """é«˜æ”»å‡»æ€§é‡‡æ ·"""
        comment_scores = []
        for comment_idx in comment_nodes:
            aggression_score = self._estimate_comment_aggressiveness(comment_idx)
            comment_scores.append((comment_idx, aggression_score))
        
        comment_scores.sort(key=lambda x: x[1], reverse=True)
        return [score[0] for score in comment_scores[:target_count]]
    
    def _balanced_sampling(self, comment_nodes: List[int], target_count: int) -> List[int]:
        """å¹³è¡¡é‡‡æ ·"""
        if len(comment_nodes) <= target_count:
            return comment_nodes
        
        interval = len(comment_nodes) / target_count
        selected = []
        
        for i in range(target_count):
            idx = int(i * interval)
            if idx < len(comment_nodes):
                selected.append(comment_nodes[idx])
        
        return selected
    
    def _estimate_comment_aggressiveness(self, comment_idx: int) -> float:
        """ä¼°è®¡è¯„è®ºçš„æ”»å‡»æ€§åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        np.random.seed(comment_idx)
        base_score = np.random.random()
        
        if comment_idx % 10 == 0:
            base_score += 0.3
        if comment_idx % 7 == 0:
            base_score += 0.2
        
        return min(1.0, base_score)
    
    def _aggregate_similarities(self, all_similarities: List[Dict]) -> List[Dict]:
        """èšåˆå¤šä¸ªå­å›¾çš„ç›¸ä¼¼åº¦ç»“æœ"""
        if not all_similarities:
            return []
        
        prototype_groups = {}
        for sim in all_similarities:
            proto_id = sim['prototype_id']
            if proto_id not in prototype_groups:
                prototype_groups[proto_id] = []
            prototype_groups[proto_id].append(sim['similarity'])
        
        aggregated = []
        for proto_id, similarities in prototype_groups.items():
            max_sim = max(similarities)
            avg_sim = np.mean(similarities)
            
            aggregated_sim = max_sim * 0.7 + avg_sim * 0.3
            
            aggregated.append({
                'prototype_id': proto_id,
                'similarity': aggregated_sim,
                'max_similarity': max_sim,
                'avg_similarity': avg_sim,
                'similarity_count': len(similarities),
                'prototype_emotion': all_similarities[0]['prototype_emotion']
            })
        
        aggregated.sort(key=lambda x: x['similarity'], reverse=True)
        return aggregated
    
    def _compute_aggregated_features(self, subgraph_results: List[Dict], aggregated_similarities: List[Dict]) -> Dict:
        """è®¡ç®—èšåˆç‰¹å¾"""
        if not subgraph_results or not aggregated_similarities:
            return self._get_default_aggregated_features()
        
        all_similarities = [sim['similarity'] for sim in aggregated_similarities]
        
        features = {
            'max_similarity': max(all_similarities),
            'avg_similarity': np.mean(all_similarities),
            'min_similarity': min(all_similarities),
            'std_similarity': np.std(all_similarities) if len(all_similarities) > 1 else 0.0,
            'prototype_0_max': 0.0,
            'prototype_1_max': 0.0,
            'prototype_0_avg': 0.0,
            'prototype_1_avg': 0.0,
            'high_similarity_count': sum(1 for sim in all_similarities if sim >= 0.7),
            'medium_similarity_count': sum(1 for sim in all_similarities if 0.3 <= sim < 0.7),
            'low_similarity_count': sum(1 for sim in all_similarities if sim < 0.3),
            'subgraph_count': len(subgraph_results),
            'avg_subgraph_size': 0.0,
            'weighted_avg_similarity': 0.0,
            'high_quality_match_count': sum(1 for sim in all_similarities if sim >= 0.8),
            'high_quality_match_ratio': 0.0,
            'top_3_avg_similarity': 0.0,
            'prototype_match_diff': 0.0
        }
        
        # è®¡ç®—æŒ‰åŸå‹åˆ†ç»„çš„ç‰¹å¾
        prototype_sims = {0: [], 1: []}
        for sim in aggregated_similarities:
            proto_id = sim['prototype_id']
            if proto_id in prototype_sims:
                prototype_sims[proto_id].append(sim['similarity'])
        
        if prototype_sims[0]:
            features['prototype_0_max'] = max(prototype_sims[0])
            features['prototype_0_avg'] = np.mean(prototype_sims[0])
        
        if prototype_sims[1]:
            features['prototype_1_max'] = max(prototype_sims[1])
            features['prototype_1_avg'] = np.mean(prototype_sims[1])
        
        # è®¡ç®—å¹³å‡å­å›¾å¤§å°
        if subgraph_results:
            subgraph_sizes = []
            for result in subgraph_results:
                subgraph = result.get('subgraph', {})
                features_dict = subgraph.get('features', {})
                size = features_dict.get('node_count', 0)
                if size > 0:
                    subgraph_sizes.append(size)
            
            if subgraph_sizes:
                features['avg_subgraph_size'] = np.mean(subgraph_sizes)
        
        # è®¡ç®—é«˜çº§ç‰¹å¾
        if all_similarities:
            weights = [sim for sim in all_similarities]
            if sum(weights) > 0:
                features['weighted_avg_similarity'] = np.average(all_similarities, weights=weights)
            else:
                features['weighted_avg_similarity'] = features['avg_similarity']
            
            if len(all_similarities) > 0:
                features['high_quality_match_ratio'] = features['high_quality_match_count'] / len(all_similarities)
            
            top_similarities = sorted(all_similarities, reverse=True)[:3]
            features['top_3_avg_similarity'] = np.mean(top_similarities)
            
            if len(prototype_sims[0]) > 0 and len(prototype_sims[1]) > 0:
                features['prototype_match_diff'] = abs(features['prototype_0_avg'] - features['prototype_1_avg'])
        
        # ç»¼åˆéœ¸å‡Œè¯„åˆ†
        features['bullying_score'] = (
            features['max_similarity'] * 0.4 +
            features['weighted_avg_similarity'] * 0.3 +
            features['high_quality_match_ratio'] * 0.2 +
            (1.0 - features['prototype_match_diff']) * 0.1
        )
        
        return features
    
    def _get_default_aggregated_features(self) -> Dict:
        """è·å–é»˜è®¤èšåˆç‰¹å¾"""
        return {
            'max_similarity': 0.0,
            'avg_similarity': 0.0,
            'min_similarity': 0.0,
            'std_similarity': 0.0,
            'prototype_0_max': 0.0,
            'prototype_1_max': 0.0,
            'prototype_0_avg': 0.0,
            'prototype_1_avg': 0.0,
            'high_similarity_count': 0,
            'medium_similarity_count': 0,
            'low_similarity_count': 0,
            'bullying_score': 0.0,
            'subgraph_count': 0,
            'avg_subgraph_size': 0.0,
            'weighted_avg_similarity': 0.0,
            'high_quality_match_count': 0,
            'high_quality_match_ratio': 0.0,
            'top_3_avg_similarity': 0.0,
            'prototype_match_diff': 0.0
        }
    
    def batch_align_sessions_optimized(self, session_ids: List[str]) -> List[Dict]:
        """æ‰¹é‡å¯¹é½ä¼šè¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        results = []
        
        print(f"ğŸ”„ å¼€å§‹ä¼˜åŒ–æ‰¹é‡å¯¹é½ {len(session_ids)} ä¸ªä¼šè¯...")
        print(f"   æ¯ä¸ªä¼šè¯é€‰æ‹© {self.optimization_config['representative_subgraph_count']} ä¸ªä»£è¡¨æ€§å­å›¾")
        print(f"   é‡‡æ ·ç­–ç•¥: {self.optimization_config['sampling_strategy']}")
        
        for i, session_id in enumerate(session_ids):
            try:
                result = self.align_session_with_prototypes_optimized(session_id)
                results.append(result)
                
                if (i + 1) % 10 == 0:
                    successful = sum(1 for r in results if r['status'] == 'success')
                    print(f"   è¿›åº¦: {i + 1}/{len(session_ids)} (æˆåŠŸ: {successful})")
                    
            except Exception as e:
                print(f"âŒ ä¼šè¯ {session_id} å¯¹é½å¤±è´¥: {e}")
                results.append({
                    'session_id': session_id,
                    'status': 'error',
                    'error': str(e),
                    'similarities': [],
                    'max_similarity': 0.0,
                    'prediction': 'normal',
                    'subgraph_count': 0
                })
        
        successful_count = sum(1 for r in results if r['status'] == 'success')
        print(f"âœ… ä¼˜åŒ–æ‰¹é‡å¯¹é½å®Œæˆï¼ŒæˆåŠŸå¤„ç† {successful_count}/{len(results)} ä¸ªä¼šè¯")
        
        return results 